{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Predicting League of Legends Match Outcomes with Logistic Regression"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "In this lab you will learn how to use Logistic Regression to predict the outcome of League of Legends match using data from the first 10 minutes of the match. League of Legends is a 5v5 team based strategy game where the objective is to destroy the other team base. Our dataset has 38 features that contain data for each team and represents to top ~2.4% players in the world.\n\n* Data Preperation\n* Logistic Regression Class\n* Training\n* Results"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Data Preperation"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "!pip install torch\nimport torch\nimport pandas as pd\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pylab as plt\ntorch.manual_seed(0)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### About the Data"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The dataset contains 39 columns, 19 for each team and 1 for the target, so we will explain the meaning of each column for a single team because they are the same but reversed for each set and the target. The data will be standardized in the dataset class."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "|  Field    |      Description      |  Unit |  Type  |\n|-----------|:-------------:|------:|--------:|\n|  blueWins |  This is our target and tell us who won the game. 1 if the blue team won and 0 if the red team won  |  1/0  |  int  |\n|  blueWardsPlaced |  Number of wards (item that gives vision) that were placed by the blue team  |  Wards  |  int  |\n|  blueWardsDestroyed |  Number of wards (item that gives vision) that were placed by the red team and destroyed by the blue team  |  Wards  |  int  |\n|  blueFirstBlood |  Tells us who got the first kill of the game. 1 for blue and 0 for red   |  1/0  |  int  |\n|  blueKills |  Number of times the blue team killed someone in the red team  |  Kills  |  int  |\n|  blueDeaths |  Number of times any player from the blue team has died either from the red team or jungle (neutral monsters)  |  Deaths  |  int  |\n|  blueAssists |  Total number of assists each player in the blue team had. An assist is when a player helps another play kill and enemy in the red team  |  Assists  |  int  |\n|  blueEliteMonsters |  Number of elite monsters killed by the blue team  |  Kills  |  int  |\n|  blueDragons |  Number of dragons killed by the blue team  | Kills   |  int  |\n|  blueHeralds |  Number of heralds killed by the blue team  |  Kills  |  int  |\n|  blueTowersDestroyed |  Number of towers belonging to the red team destroyed by the blue team  |  Towers  |  int  |\n|  blueTotalGold |  Total amount of gold each player in the blue team has  |  Gold  |  int  |\n|  blueAvgLevel |  Avg Champion level of the blue team  |  Level  |  float  |\n|  blueTotalExperience |  Total amount of experience each player in the blue team has  |  Experience  |  int  |\n|  blueTotalMinionsKilled |  Total amount of minions killed by each player in the blue team  |  Kills  |  int  |\n|  blueTotalJungleMinionsKilled |  Total amount of jungle monsters killed by each player in the blue team  |  Kills  |  int  |\n|  blueGoldDiff |  Difference between the total gold of the red and blue team  |  Gold  |  int  |\n|  blueExperienceDiff |  Difference between the total experience of the red and blue team  |  Experience  |  int  |\n|  blueCSPerMin |  Number of minions or jungle monsters killed per minute  |  Kills/Min  |  float  |\n|  blueGoldPerMin |  How much gold the team receives per minute  |  Gold/Min  |  float  |\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Dataset Class"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "class Dataset(Dataset):\n\n    # Constructor\n    def __init__(self, train = True):\n        \n        data = pd.read_csv('https://s3.us.cloud-object-storage.appdomain.cloud/cf-courses-data/CognitiveClass/DL0110EN/ML03210EN_Final_Assignment/LoLMatchData.csv')\n        \n        if (train):\n            self.x = torch.tensor(data.iloc[0:7903, :].drop(['blueWins'], axis=1).values, dtype=torch.float)\n            # standardizing the data\n            self.x = (self.x - self.x.mean(dim=0))/self.x.std(dim=0)\n            self.y = torch.tensor(data.loc[0:7903, 'blueWins'].values, dtype=torch.float).reshape((7904,1))\n            self.len = self.x.shape[0]\n        else:\n            self.x = torch.tensor(data.iloc[7904:, :].drop(['blueWins'], axis=1).values, dtype=torch.float)\n            # standardizing the data\n            self.x = (self.x - self.x.mean(dim=0))/self.x.std(dim=0)\n            self.y = torch.tensor(data.loc[7904:, 'blueWins'].values, dtype=torch.float).reshape((1975,1))\n            self.len = self.x.shape[0]\n            \n    \n    # Get the length\n    def __len__(self):\n        return self.len\n    \n    # Getter\n    def __getitem__(self, idx):\n        \n        x = self.x[idx]\n        \n        y = self.y[idx]\n\n        return x, y"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Question 1"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Using the Dataset class defined above create dataset object for training and testing data called data_train and data_test. Remember to set the train parameter to the correct value."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Question 2"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Using the Dataset objects created above create data loaders for each dataset called train_loader and test_loader. Set the batch_size parameter to 100."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Logistic Regression Class"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Defined below is our Logistic Regression class which will basically perform linear regression using the linear layer and then using the sigmoid activation function we can perform logistic regression."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "class LogisticRegression(nn.Module):\n    \n    def __init__(self, input_dimension, output_dimension):\n        super(LogisticRegression, self).__init__()\n        self.linear = nn.Linear(input_dimension, output_dimension)\n    \n    def forward(self, x):\n        x = torch.sigmoid(self.linear(x))\n        return x"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "model = LogisticRegression(38, 1)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Training"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Optimizer and Loss Function"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Question 3"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Before we can get to training we must define the optimizer and the loss function we will use to train our model. Please create an optimizer called optimizer that uses SGD with a learning rate of .001 and a loss function called criterion that uses BCELoss."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Training Function"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def train(model, optimizer, criterion, train_loader, test_loader, epochs):\n    cost_list = []\n    accuracy_list = []\n    \n    for epoch in range(epochs):\n        \n        # variable to keep track of cost (total loss)\n        cost = 0\n        model.train()\n        \n        for x, y in train_loader:\n            \n            # clears gradients from last step\n            optimizer.zero_grad()\n            \n            # uses model to predict target for x\n            z = model(x)\n\n            # calculates loss between prediction and ground truth\n            loss = criterion(z, y)\n\n            # calculates the derivative of the loss with respect to each parameter\n            loss.backward()\n            \n            # updates each parameter using the optimizer algorithm and values calculated from loss.backward()\n            optimizer.step()\n            \n            # increment cost\n            cost += loss.item()\n        \n        # variable to keep track of correct prediction in the test set\n        correct = 0\n        model.eval()\n        \n        for x_test, y_test in test_loader:\n            \n            # uses model to predict target for x_test\n            z = model(x_test)\n            \n            # rounds the output to the nearest int because our target is either 0 or 1 and the output is a probability between 0 and 1\n            z = torch.round(z)\n            \n            # find our how many in the batch were corrent and adds it to the total for the epoch\n            correct += (z == y_test).sum().item()\n        \n        # calculates the accuracy rate in the test data\n        accuracy = correct / len(data_test)\n        \n        # appends the accuracy and cost to the list to keep track\n        accuracy_list.append(accuracy)\n        cost_list.append(cost)\n    \n    return accuracy_list, cost_list\n        "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Question 4"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Using the training function defined above, the model, criterion, and optimizer that you created before train the model for 10 epochs. Save the accuracy and cost returned to lists called accuracy_list and cost_list."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Results"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "fig, ax1 = plt.subplots()\ncolor = 'tab:red'\nax1.plot(cost_list, color=color)\nax1.set_xlabel('epoch', color=color)\nax1.set_ylabel('Cost', color=color)\nax1.tick_params(axis='y', color=color)\n    \nax2 = ax1.twinx()  \ncolor = 'tab:blue'\nax2.set_ylabel('accuracy', color=color) \nax2.set_xlabel('epoch', color=color)\nax2.plot( accuracy_list, color=color)\nax2.tick_params(axis='y', color=color)\nfig.tight_layout()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h3>Thanks for completing this lesson!</h3>\n\n<h4>Authors: <a href=\"https://www.linkedin.com/in/azim-hirjani-691a07179/\">Azim Hirjani</a>\n\n\n\n<hr>\n\n<p>Copyright &copy; 2018 <a href=\"https://cocl.us/DX0108EN_CC\">Cognitive Class</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>.</p>"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python",
            "language": "python",
            "name": "conda-env-python-py"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}